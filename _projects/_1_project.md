---
layout: page
title: Toward Efficient Software Engineering Automation
description: Advancing Efficient and Sustainable Software Engineering Automation via, Quantization, Knowledge Distillation and PEFT
img: assets/img/sustainability/main.png
importance: 1
category: work
related_publications: false
---

As the demand for automated solutions in software engineering continues to rise, the efficiency of training and deploying large language models (LLMs) becomes a critical concern. Efficient software engineering automation aims to tackle this challenge by adopting techniques that optimize resource utilization while preserving high performance.

Parameter-Efficient Fine-Tuning (PEFT) allows large models to be adapted to new tasks by updating only a small portion of their parameters, significantly lowering computational overhead. Quantization reduces model size and accelerates inference by decreasing numerical precision, all while maintaining acceptable levels of accuracy. Knowledge distillation transfers the capabilities of a large model into a smaller, faster one, preserving much of the original performance at a fraction of the computational cost.

Our ongoing research investigates the use and combination of these methods to develop efficient, cost-effective, and scalable approaches for automating software engineering tasksâ€”advancing practical, high-performance AI-driven development workflows.

---

<div class="row">
    <div class="col-sm mt-9 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/sustainability/cost-llm.jpg" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>


